# CPSF — One‑Shot Online Memory (QTail) + Direct Projection & Layer Stacking (Formal)

**Статус:** строгая формализация (определения, теоремы, доказательства, алгоритмика).  
**Канон:** не вводим новых сущностей сверх уже зафиксированных: вклад $C_j=(z_j,\vec d_j,\hat T_j,\sigma_{\parallel j},\sigma_{\perp j},\alpha_j)$; позиция — «$n{=}0$+хвост»; хвост — 1D-квадратура Гаусса–Лагерра порядка $Q$; оффлайн матрица $H$, онлайн вектор $\psi$; вес $w_j$, поле $T=w^\top X$ при $X[j,:]\equiv \hat T_j^\top$.

---

## 0. Обозначения
- Размерности: $N$ — исходная, $D:=2N$, $\nu:=\tfrac D2-1$, $M$ — число вкладов, $S$ — размер семантики.  
- Позиция: $x:=z_j-z\in\mathbb R^D$, $u_j:=\vec d_j/\|\vec d_j\|$, $c:=\langle x,u_j\rangle$, $r:=\|x\|$.  
- Анизотропия: $a_j:=\sigma_{\perp,j}^{-2}$, $b_j:=\sigma_{\parallel,j}^{-2}-\sigma_{\perp,j}^{-2}$, $\kappa_j:=b_j/a_j$, $G_j:=a_j I+b_j u_ju_j^\top$.  
- Константа: $K_D(a):=\dfrac{2\pi^{D/2}}{\Gamma(D/2)}\,(\pi a)^{-D/2}\,2^{\nu}\,\Gamma(D/2)$.  
- Квадратура Гаусса–Лагерра с параметром $\alpha=\nu$: узлы/веса $\{(u_q,w_q^{(\nu)})\}_{q=1}^Q$.

---

## 1. QTail‑разложение позиционной периодизации

**Определение 1 (позиционная часть).** Для вклада $j$:
$$
A_{\mathrm{pos},j}(z):=\exp\!\big(-\pi\,x^\top G_j x\big),\qquad x=z_j-z.
$$

**Предложение 1 (разделение «$n{=}0$+хвост»).** Позиционная периодизация имеет вид
$$
\Theta^{(\mathrm{pos})}_j(z)=A_{\mathrm{pos},j}(z)\,[1+\,\mathcal T_j(z)],
$$
где хвост $\mathcal T_j$ представим интегралом по радиусу $\rho$ после углового усреднения, и при замене $u=\pi a_j\rho^2$ сводится к интегралу Гаусса–Лагерра:
$$
\mathcal T_j(z)=K_D(a_j)\int_{0}^{\infty} u^{\nu}e^{-u}\,\Phi_j(u;z)\,du,
$$
$$
\Phi_j(u;z):=\underbrace{{}_1F_1\!\Big(\tfrac12;\tfrac D2; -\kappa_j u\Big)}_{\text{анизотропия}}\cdot\underbrace{\zeta_j(u)^{-\nu} I_{\nu}\!(\zeta_j(u))}_{\text{радиальная часть}},\ \
\zeta_j(u):=2\sqrt{\pi}\,m_j(z)\,a_j^{-1/2}\,u^{1/2},\ \ m_j(z):=\|a_j x + b_j c\,u_j\|.
$$
*Доказательство.* Выделение члена $n=0$ даёт $A_{\mathrm{pos},j}$. Остаток по $n\ne0$ группируется по оболочкам с радиусом $\rho=\|n\|$; угловые средние экспонент квадратичной формы и линейной формы дают соответственно ${}_1F_1$ и $I_{\nu}$. Замена переменной сводит радиальный интеграл к GL‑форме. □

**Теорема 1 (QTail‑квадратура).** Пусть $Q\in\mathbb N$. Тогда
$$
\boxed{\;\Theta^{(\mathrm{pos})}_j(z)\;=\;A_{\mathrm{pos},j}(z)\Big[1+K_D(a_j)\sum_{q=1}^Q w_q^{(\nu)}\,\Phi_j(u_q;z)\Big]\; +\; R_Q^{(j)}(z),\ }
$$
причём остаток $\sup_z|R_Q^{(j)}(z)|\to0$ при $Q\to\infty$ сверхбыстро (экспоненциально) благодаря аналитичности $\Phi_j$ и экспоненциальному весу $u^{\nu}e^{-u}$.

*Доказательство.* Стандартная оценка точности квадратуры Гаусса–Лагерра для аналитических подынтегральных функций под весом $u^{\nu}e^{-u}$. □

---

## 2. Вес вклада, поле, линейность

**Определение 2 (вес, поле).**
$$
C^{(\mathrm{dir})}_j(\delta\vec d):=\exp\!\big(-\pi\,\delta\vec d^\top A^{(\mathrm{dir})}_j\,\delta\vec d\big),\qquad
w_j(z,\vec d):=\alpha_j\,\mathrm{Re}\,\Big(C^{(\mathrm{dir})}_j(\delta\vec d)\,\Theta^{(\mathrm{pos})}_j(z)\Big),
$$
$$
T(z,\vec d)=\sum_{j=1}^M w_j(z,\vec d)\,\hat T_j\quad(\equiv w(z,\vec d)^\top X,\ X[j,:]=\hat T_j^\top).
$$

**Следствие 1 (QTail‑форма веса).** По Теореме 1:
$$
\boxed{\;w_j(z,\vec d)=\alpha_j\,\mathrm{Re}\,\Big(C^{(\mathrm{dir})}_j\,A_{\mathrm{pos},j}\,[\,1+H_{j,:}\,\psi_j(z)\,]\Big)\; +\; \tilde R_Q^{(j)}(z,\vec d),\ }
$$
где оффлайн‑матрица
$$H_{j,q}:=K_D(a_j)\,w_q^{(\nu)}\,{}_1F_1\!\Big(\tfrac12;\tfrac D2; -\kappa_j u_q\Big),\quad H\in\mathbb R^{M\times Q},$$
а онлайн‑вектор
$$\psi_j(q):=\zeta_j(u_q)^{-\nu}\,I_{\nu}\!(\zeta_j(u_q)).$$

**Замечание.** Погрешность $\tilde R_Q^{(j)}$ наследует скорость сходимости $R_Q^{(j)}$ и убывает при росте $Q$.

---

## 3. Оффлайн пред‑расчёт и хранимые данные

**Шаги оффлайна (one‑shot):**
1) Узлы/веса GL: $\{(u_q,w_q^{(\nu)})\}_{q=1}^Q$ (фиксируются для данного $D$).  
2) Для каждого $j$: скаляры $a_j,b_j,\kappa_j,K_D(a_j)$.  
3) Матрица $H\in\mathbb R^{M\times Q}$ по формуле выше.  
4) Канонные $\alpha_j\in\mathbb R$, $\hat T_j\in\mathbb C^S$ (то есть $X$).

**Что храним:** $u\in\mathbb R^Q$, $w\in\mathbb R^Q$, $H\in\mathbb R^{M\times Q}$, и $\{\alpha_j,\hat T_j\}$. Больше ничего.

---

## 4. Онлайн вычисление (любой запрос)
Для каждого $j$:
- Вычислить $A_{\mathrm{pos},j}(z)$ и $\psi_j\in\mathbb R^Q$;
- Скаляр $S_j:=H_{j,:}\,\psi_j$;
- Вес $w_j=\alpha_j\,\mathrm{Re}\,(C^{(\mathrm{dir})}_j\,A_{\mathrm{pos},j}(1+S_j))$;
- Поле $T=w^\top X$.

**Сложность:** $O(MQ)$ вызовов $I_\nu$+умножений и $O(MS)$ линейной сборки $T$. Память на запрос: $O(Q)+O(S)$.

---

## 5. Аналитическая проекция ошибки (без backprop)

Пусть дан «таргет» $T^\star\in\mathbb C^S$ для текущего запроса, $e:=T^\star-T$.

**Определение 3 (проектор словаря).** $G:=X X^\top\in\mathbb C^{M\times M}$. Если $G$ обратима, положим
$$P:=X^\top G^{-1}X\in\mathbb C^{S\times S}.$$
В общем случае используем псевдообратную $X^{\dagger}$ и $P:=X^\top X^{\dagger}{}^\top$ (ортопроектор на $\mathrm{Im}(X^\top)$).

**Теорема 2 (one‑shot коррекция).** Вектор
$$\delta w:=G^{-1}X\,e\quad(\text{или }\delta w:=X^{\dagger}{}^\top e)$$
минимизирует $\|X^\top\delta w-e\|_2$. Скорректированный ответ
$$T_{\mathrm{new}}:=T+X^\top\delta w=T+Pe$$
является ортогональной проекцией $T^\star$ на $\mathrm{Im}(X^\top)$; в частности, если $\mathrm{rank}(X)=S$, то $P=I$ и $T_{\mathrm{new}}=T^\star$ за один шаг.

*Доказательство.* Классическая нормальная система $XX^\top\delta w=Xe$; свойства $P$ как ортопроектора следуют из $P^2=P$, $P^\ast=P$. □

**Практика.** Можно возвращать $T_{\mathrm{new}}$ (не меняя параметров), либо использовать $\delta w$ как динамический вес $w^{\mathrm{eff}}=w+\delta w$.

---

## 6. Стек слоёв (динамическая архитектура без backprop)

Пусть есть слои $\ell=1,\dots,L$ с собственными словарями $X^{(\ell)}$ (строки — $\hat T_j^{(\ell)}$) и своими $H^{(\ell)}$. Для $(z,\vec d)$:

- Базовый прогноз слоя: $T^{(\ell)}=(w^{(\ell)})^\top X^{(\ell)}$.  
- Остаток на входе слоя: $r^{(\ell)}=T^\star-\sum_{k<\ell}\big(T^{(k)}+P^{(k)}r^{(k)}\big)$.  
- Проекция: $P^{(\ell)}:=X^{(\ell)\top}(X^{(\ell)}X^{(\ell)\top})^{-1}X^{(\ell)}$.  
- Выход слоя: $\tilde T^{(\ell)}:=T^{(\ell)}+P^{(\ell)} r^{(\ell)}$.

**Определение 4 (ортогонализованный стек).** Рекурсивно положим $\widetilde X^{(1)}:=X^{(1)}$, а для $\ell\ge2$:
$$\widetilde X^{(\ell)}:=X^{(\ell)}\,(I-\sum_{k<\ell}P^{(k)}),\qquad P^{(\ell)}:=\widetilde X^{(\ell)\top}\big(\widetilde X^{(\ell)}\widetilde X^{(\ell)\top}\big)^{-1}\widetilde X^{(\ell)}.$$
Тогда подпространства $\mathrm{Im}(\widetilde X^{(\ell)\top})$ попарно ортогональны.

**Теорема 3 (точность стека).** Пусть $V:=\sum_{\ell=1}^L \mathrm{Im}(\widetilde X^{(\ell)\top})$. Тогда итог
$$T_{\mathrm{stack}}:=\sum_{\ell=1}^L \tilde T^{(\ell)}$$
является ортопроекцией $T^\star$ на $V$. В частности, если $V=\mathbb C^S$ (ранг объединённого словаря равен $S$), то $T_{\mathrm{stack}}=T^\star$.

*Доказательство.* Ортопроекции на взаимно ортогональные подпространства коммутируют и суммируются в проекцию на их сумму. По определению $\widetilde X^{(\ell)}$ подпространства ортогональны; сумма выходов — проекция на $V$. □

**Следствие 2 (монотонная редукция остатка).** Без ортогонализации норма остатка после $L$ слоёв равна $\|(I-P^{(L)})\cdots(I-P^{(1)})T^\star\|_2$ и невозрастает при добавлении слоя.

---

## 7. Инкрементальные апдейты (динамика)

**Добавление вклада в слое $\ell$.** Достраиваем строку $H_{m+1,:}^{(\ell)}$ и вектор $\hat T_{m+1}^{(\ell)}$. Матрица $G^{(\ell)}=X^{(\ell)}X^{(\ell)\top}$ обновляется ранга‑1 формулой Шермана–Моррисона; $P^{(\ell)}$ обновляется соответственно.

**«Материализация» коррекции.** Для персистентности $Pe$ можно добавить узкий вклад $\tilde C$ с $\hat T_{\tilde j}\propto e$ (или его орто‑компонентой относительно текущего $V$), что расширяет словарь и делает последующие коррекции дешевле.

---

## 8. Сложность и память

- **Оффлайн:** построение $H$: $O(MQ)$ вызовов ${}_1F_1$ + линейная склейка; память — $H\in\mathbb R^{M\times Q}$, узлы/веса, $\{\alpha_j,\hat T_j\}$.  
- **Онлайн (за запрос):** $O(MQ)$ на $\psi$ и $H\psi$ + $O(MS)$ на сборку $T$; проекционная коррекция — $O(MS)$ при хранении $G^{-1}$.  
- **Стек из $L$ слоёв:** стоимость суммируется по слоям; ортогонализацию можно выполнить оффлайн.

---

## 9. Достижимость минимумов и обучаемость

**Теорема 4 (достижимость целевого ответа без backprop).** Если для некоторого $L$ выполнено $\sum_{\ell=1}^L \mathrm{Im}(\widetilde X^{(\ell)\top})=\mathbb C^S$, то для любого $T^\star\in\mathbb C^S$ и любого запроса $(z,\vec d)$ существует конечная композиция слоёв и их one‑shot коррекций, дающая $T_{\mathrm{stack}}=T^\star$ ровно за один «проход» по слоям (без backprop).  
*Доказательство.* Теорема 3 для $V=\mathbb C^S$. □

**Теорема 5 (универсальность при расширении словаря).** Пусть $\{X^{(\ell)}\}_{\ell\ge1}$ — последовательность словарей, ранги которых растут и объединённая оболочка плотна в $\mathbb C^S$. Тогда последовательность стека $T_{\mathrm{stack}}^{(L)}$ сходится к $T^\star$ по норме при $L\to\infty$.  
*Доказательство.* Проекции на возрастающие подпространства сходятся к проекции на замыкание их суммы; при полноте — к $T^\star$. □

---

## 10. Резюме (в строгости)

- **QTail** редуцирует многомерную позиционную периодизацию к **1D‑квадратуре** и даёт вес $w_j$ в форме «экспонента × (1 + скалярное произведение)»;
- **Оффлайн‑память** — только $H$ и канонные $\{\alpha_j,\hat T_j\}$; **онлайн** — $O(MQ)+O(MS)$;
- **Аналитическая коррекция** $T\mapsto T+Pe$ даёт точный минимум в подпространстве словаря за один шаг;  
- **Стек слоёв** (с ортогонализацией) даёт точную проекцию на сумму подпространств и, при полноте, **точное совпадение** с $T^\star$ без backprop;  
- **Динамика**: добавление вклада/слоя — ранговые апдейты и расширение словаря; обучение — последовательность аналитических проекций и (опционально) материализация коррекций.

> Тем самым, в рамках канона CPSF получен формальный каркас «обучаемого универсального вычислителя» с динамической природой и практически линейной сложностью: тяжёлая геометрия вынесена в оффлайн‑$H$, онлайн — линейные операции и стабильные спец‑функции; обучение — точные ортопроекции без обратного распространения.

