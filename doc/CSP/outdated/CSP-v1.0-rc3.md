# Compact Spectral Projector (CSP)

*Technical Design Document Â· **Version 1.0â€‘rc3** (Juneâ€¯2025)*

---

## Changeâ€‘Log & Compilation Rationale

This document merges **all publicly released drafts** of SCP (v0.9a â†’ v1.0â€‘rc2) together with the **expert critique** from *critic.txt*. Newer formulations supersede older ones, while unique legacy details are preserved in notes. Critique items are summarised in Â§21 and open issues in Â§22.

---

## 1 Â· Purpose

CSP is a **dropâ€‘in, parameterâ€‘efficient replacement for explicit bilinear or multiâ€‘linear weight tensors**.  It approximates the interaction of two **or more** arbitrary tensors by the pipeline

> **Countâ€‘Sketch â†’ FFT â†’ Hadamard product â†’ IFFT**

Key traits: multiâ€‘head/multiâ€‘rank grouping, complexâ€‘number support, *bake* step to shrink trainâ€‘time parameters into hash tables for inference, FX/ONNX friendliness and optional learnable projection matrices.

Typical useâ€‘cases

* Dynamic weight generators (e.g. `TensorComposerMobius`).
* Multiâ€‘modal attention (vision Ã— text Ã— audio).
* Graph/relational scoring & link prediction.
* Parameterâ€‘efficient fineâ€‘tuning inside Transformer/LLM blocks.

---

## 2 Â· Compact Bilinear Pooling â€” Heritage & Limitations

| Aspect           | Classic CBP (ECCVâ€‘16)                 | Limitation â†’ CSP Fix                      |
| ---------------- | ------------------------------------- | ------------------------------------------ |
| **Compression**  | Â±1 Countâ€‘Sketch, `FFT âˆ˜ IFFT`         | Fixed dim, twoâ€‘input only                  |
| **Learnability** | Random, *frozen* hash tables          | **Learnable** sketches + optional freezing |
| **Input shape**  | Flat 2â€‘D feature maps                 | Retains Nâ€‘D, head & rank dims              |
| **Scalability**  | OK for small C; degrades âˆ headsÃ—rank | Group routing + bake                       |
| **Deployment**   | Reâ€‘generate full hash tables          | Bake to int8 `(h,s)` + 2â€‘byte gains        |

---

## 3 Â· Primary Objective

> **Create a universal projector for Nâ€‘D, multiâ€‘head, multiâ€‘rank tensors offering**
>
> 1. **Affine equivariance** to head / rank permutation;
> 2. **Adjustable compression** via sketch dim â†” error bound;
> 3. **Learnability â†’ Bakeability**: dense, trainable during learning â†’ ultraâ€‘compact at inference.

---

## 4 Â· Key Architectural Innovations (v1.0 additions)

| Block                       | Function                                                                             | Design Options                                                   |
| --------------------------- | ------------------------------------------------------------------------------------ | ---------------------------------------------------------------- |
| **Parametric Countâ€‘Sketch** | Replace frozen `(h,s)` with matrices **A** (magnitude) & **B** (phase/sign).         | `typeâˆˆ{binary, gaussian, orthogonal}`, `learnableâˆˆ{False, True}` |
| **Multiâ€‘Input Fusion**      | Generalise bilinear interaction to **K â‰¥ 2** tensors.                                | Hadamard product in Fourier domain                               |
| **Head/Rank Routing**       | Separate projector group per `(head, subspace, rank)`; optional soft/Gumbel routing. |                                                                  |
| **Adaptive Output Mask**    | Learns Î» âˆˆ [0,1] suppressing dead coordinates â†’ can be pruned.                      |                                                                  |
| **Lossâ€‘Aware Scaling**      | Gradientâ€‘variance normalisation (BGN / LayerNorm).                                   | Critical for `output_dimâ‰¥1024`                                   |

> **â„¹ Legacy note (v0.9a):** early drafts lacked adaptive mask & routing and used fixed binary sketches.

---

## 5 Â· Design Goals (consolidated)

| ID | Goal                         | Rationale                                                    |
| -- | ---------------------------- | ------------------------------------------------------------ |
| G1 | Arbitrary axis pairing       | Avoid flattening whole tensor; works on any pair(s) of axes. |
| G2 | Massive head/rank support    | Thousands of groups without weight duplication.              |
| G3 | Trainable â†’ Baked switch     | Dense params while training, â‰¤â€¯1â€¯KiB per head at inference.  |
| G4 | Complex number support       | Required by MÃ¶biusâ€‘style models; maintain correct gradients. |
| G5 | FX/TorchScript & ONNX export | Pure `aten` ops only.                                        |
| G6 | Extensible cascade / Nâ€‘ary   | Supports sequential or Nâ€‘ary CBP.                            |

---

## 6 Â· Theoretical Foundations

### 6.1 Unbiasedness & Variance (from v1.0)

Let **Î¦** denote the Countâ€‘Sketch â†’ FFT embedding with random hash **h** and sign **s**.  For real vectors **x**, **y** âˆˆ â„áµˆ:

$$
\mathbb{E}_{h,s}[\langle Î¦(x), Î¦(y) \rangle] = \langle x, y \rangle,\qquad
\operatorname{Var}[\langle Î¦(x), Î¦(y) \rangle] \le \frac{\|x\|^2\,\|y\|^2}{dâ€²}.
$$

Hence MSE decays as *O*(1/dâ€²).  For Kâ€¯â‰¥â€¯2 tensors the result generalises by multilinearity.

### 6.2 Choice of Projection Matrices (incl. critic suggestions)

* **Binary Â±1** â€“ memory optimal; scatterâ€‘add friendly.
* **Gaussian** â€“ lower variance but fp16/32 memory.
* **Orthogonal** â€“ â„“â‚‚â€‘norm preserving; oneâ€‘off QR/Hadamard cost.
* **Learnable** â€“ initialise binary; optimise fine grained structure (cf. *Learning to Sketch*, ICML 2020).

### 6.3 Sparse & Structured Data

Sketch stage with scatterâ€‘add touches only `nnz(x)` bins â†’ linear cost in sparsity.  For >95â€¯% sparse data choose binary projection to avoid dense matmul.

---

## 7 Â· Hyperâ€‘parameter Guidelines

| Symbol             | Meaning                        | Default         | Tuning hint                       |
| ------------------ | ------------------------------ | --------------- | --------------------------------- |
| *dâ€²*               | Sketch size (`output_dim`)     | 512             | Îµâ‰ˆ0.1 â†’â€¯dâ€²â‰ˆ300; Îµâ‰ˆ0.05 â†’â€¯dâ€²â‰ˆ1200  |
| *G*                | Heads Ã— Subspaces Ã— Ranks      | modelâ€‘dependent | Keep `Gâ‰¤4â€¯k` or merge tiny groups |
| `projection_type`  | binary / gaussian / orthogonal | binary          | gaussian when gradients noisy     |
| `learnable_sketch` | Train **A,B**?                 | True            | Freeze then bake for inference    |
| BGN position       | Norm placement                 | after IFFT      | try preâ€‘FFT if gradients explode  |

Quick heuristic: `dâ€² â‰ˆ 4Â·âˆš(d_in)`.

---

## 8 Â· Highâ€‘Level Architecture

```
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ AxisGather â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  A_sel  B_sel   (B, G, d_A/B)  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
              â”‚  (train â‡„ baked switch)
        (A,B) dense â‡„ (h,s) lookup
              â–¼
    â•­â”€ Countâ€‘Sketch Projector â”€â•®
    â”‚   Xâ€²    Yâ€²  (B, G, dâ€²)  â”‚
    â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
              â”‚  FFT / âŠ™ / IFFT
              â–¼
       PostScale Â· BGN / Norm
              â”‚
     Reshape to userâ€‘defined out
```

**Group dimension** `G = heads Ã— subspaces Ã— ranks`; complex inputs split Re/Im before sketch.

---

## 9 Â· Public API (PyTorch)

```python
class CSP(nn.Module):
    def __init__(
        self,
        shape_A: tuple[int, ...],
        shape_B: tuple[int, ...],
        axes: list[tuple[int, int]],
        group_shape: int | tuple[int, ...] = 1,
        output_dim: int = 512,
        projection_type: str = "binary",  # "gaussian"|"orthogonal"
        learnable_sketch: bool = True,
        learnable_phase: bool = False,
        complex_weights: bool = False,
        dtype: torch.dtype = torch.float32,
    ):
        """Initialise CSP layer.
        *projection_type* chooses distribution of A/B.
        *learnable_phase* allows the sign/phase to adapt during training.
        """

    def forward(
        self,
        A: torch.Tensor,
        B: torch.Tensor,
        *extra: torch.Tensor,
    ) -> torch.Tensor:
        """Compute CBP.  If *extra* tensors are given the layer performs
        Kâ€‘ary fusion (experimental)."""

    @torch.no_grad()
    def bake_sketch(self, method: str = "greedy", iters: int = 2) -> None:
        """Quantise *(A,B)* â†’ (h,s) and switch to inference mode."""

    def export_state(self) -> dict[str, torch.Tensor]: ...
    def import_state(self, state: dict[str, torch.Tensor]) -> None: ...
```

---

## 10 Â· Internal Components

| Component           | Trainâ€‘time                                | Inferenceâ€‘time             |
| ------------------- | ----------------------------------------- | -------------------------- |
| **AxisGather**      | `permute`, `reshape`                      | same                       |
| **SketchProjector** | dense `A`, `B` (â„‚) + SGD                  | `(h:int16, s:int8)` lookup |
| **FFTCore**         | `torch.fft.rfft/irfft`                    | identical                  |
| **PostScale**       | learnable scale, optional BGN / LayerNorm | same                       |

> **Legacy addition (v0.9a):** early prototypes used a separate `CountSketchProjector` for each tensor.  Current design shares code via template class.

---

## 11 Â· Algorithms

### 11.1 Training Forward (real case)

```python
# Gather & maybe split complex parts
a = axis_gather(A)   # (B, G, dA)
b = axis_gather(B)   # (B, G, dB)
# Signed scatterâ€‘add (Countâ€‘Sketch)
Xa = scatter_add_signed(a, h_a, s_a, d_prime)
Yb = scatter_add_signed(b, h_b, s_b, d_prime)
# Frequencyâ€‘domain product
Zf = torch.fft.rfft(Xa) * torch.fft.rfft(Yb)
Z  = torch.fft.irfft(Zf, n=d_prime)
Z  = post_scale(Z)  # scale Â· optional LayerNorm / BGN
return reshape_back(Z)
```

For **complex inputs** split into Re/Im before sketch and recombine after IFFT.

### 11.2 Greedy Bake

Identical to v0.9a: pick maxâ€‘magnitude bin per row â†’ store `(h,s)`; optional second pass redistributes residual.

### 11.3 Inference Scatterâ€‘Add (per group)

```python
out = torch.zeros(B, d_prime, device=x.device)
idx = h.expand(B, -1)
sgn = s.float().expand_as(x_in)
out.scatter_add_(1, idx, sgn * x_in)
```

Cost O(batch Ã— d_in).

---

## 12 Â· Performance & Memory

*Train*: activations â‰ˆ `BÂ·GÂ·dâ€²`.  With `output_dim  â‰¤ 1â€¯k` and `Gâ‰ˆ2â€¯k` fits into 80â€¯G GPU.

*Inference (baked)*: per head â‰ˆ `(d_inÂ·3 bytes + dâ€²Â·2 bytes)`.

FFT time: `2Â·BÂ·GÂ·dâ€²Â·logâ‚‚(dâ€²)`; empirical â€‘1.3â€¯Ã— faster than GEMM at `dâ€²=512`, `G=256`.

*Legacy note*: v0.9a reported similar asymptotics but with `dâ€²â‰¤512` to fit on A100 80G; numbers have been reâ€‘validated.

---

## 13 Â· Error Handling

| Condition                     | Behaviour                   |
| ----------------------------- | --------------------------- |
| Unsupported `projection_type` | `ValueError`                |
| dtype âˆ‰ {fp16, fp32, bf16}    | Autoâ€‘cast to fp32 + warning |
| `bake_sketch()` on baked      | Emit warning, noâ€‘op         |
| Axis mismatch                 | `ValueError` in `__init__`  |

---

## 14 Â· Testing & Benchmarking Strategy

1. **Shape fuzzing** â€“ random tensors & axis pairs.
2. **Gradient check** â€“ autograd vs finite diff.
3. **Equivalence** â€“ compare with explicit bilinear on toy dims.
4. **Bake regression** â€“ MSE before/after bake â‰¤â€¯Îµ.
5. **Benchmark suite** â€“ CUBâ€‘200, VQAâ€‘2.0, synthetic sparse; metrics: RMSE, throughput, memory.
6. **Ablations** â€“ `projection_type`, learnable vs frozen, BGN placement.

Scripts under `bench/` (v1.0) supersede earlier `tests/` folder (v0.9a).

---

## 15 Â· Implementation Roadmap

| Milestone | Deliverable                              | Status / ETA |
| --------- | ---------------------------------------- | ------------ |
| M1        | v1.0 core (binary projection, learnable) | **done**     |
| M2        | Gaussian / orthogonal variants           | +1â€¯wk        |
| M3        | ILP bake optimiser                       | +2â€¯wk        |
| M4        | Public benchmark release                 | +4â€¯wk        |
| M5        | Integration into `TensorComposerMobius`  | +5â€¯wk        |

---

## 16 Â· Dependencies

* **PyTorch â‰¥â€¯2.3** (`torch.fft` API)
* **NumPy** (offline tools)
* *(optional)* `einops` for readable reshapes (kept off hotâ€‘path)

---

## 17 Â· Known Limitations

* Gradients unavailable after `bake()` â†’ keep layer in `eval()` for inference.
* FFT may underperform for `output_dim < 16`; fallback to dense matmul.
* Greedy bake leaves â‰ˆâ€¯5â€¯% MSE; ILP bake WIP.

---

## 18 Â· Advanced Features (from v0.9a)

| Feature                  | Usage                                                   |
| ------------------------ | ------------------------------------------------------- |
| **Cascade mode**         | `cascade=[[(a1,b1)], [(a2,b2)]]` â†’ two CBP passes.      |
| **Nâ€‘ary CBP**            | Provide â‰¥3 tensors to `forward()` (experimental).       |
| **Veryâ€‘lowâ€‘rank LoRA**   | `output_dim â‰¤ 64` â†’ baked sizeâ€¯<â€¯1â€¯KiB per head.        |
| **Auto dtypeâ€‘cast**      | Inputs promoted to `dtype`; FFT runs in fp32 if needed. |
| **FX/TorchScript ready** | Only `aten` ops (`scatter_add`, `fft_fft`, `fft_ifft`). |

---

## 19 Â· Quick Examples

### 19.1 Singleâ€‘Head, Latent Ã— Channel

```python
layer = CSP(
    shape_A=(B, T, H, W, D),
    shape_B=(B, T, H, W, D),
    axes=[(4, 4)],  # D â†” D
    group_shape=1,
    output_dim=512,
    complex_weights=True,
)
Z = layer(A, B)  # â†’ (B, 512)
```

### 19.2 Replacing Qâ€‘K dot in Transformer

```python
cbp = CSP(
    shape_A=(B, Heads, S, D),
    shape_B=(B, Heads, S, D),
    axes=[(3, 3)],
    group_shape=Heads,
    output_dim=64,
)
attn_logits = cbp(Q, K) / math.sqrt(D)
```

---

## 20 Â· Application Scenarios (unchanged)

| ID | Scenario                         | Design Impact                                     |
| -- | -------------------------------- | ------------------------------------------------- |
| U1 | Video spatioâ€‘temporal fusion     | Needs cascade API (HÃ—W then TÃ—C).                 |
| U2 | Knowledgeâ€‘graph relation scoring | Emphasise bake(); int8 buffers; tiny edge models. |
| U3 | LoRAâ€‘style fineâ€‘tuning           | `output_dim â‰¤ 32`; FFT fallback.                  |
| U4 | Crossâ€‘modal VQA                  | Large G; ensure CUDA scatterâ€‘add scales.          |
| U5 | Complexâ€‘valued geometric nets    | Preserve Re/Im gradients correctly.               |

---

## 21 Â· Expert Critique & Recommendations (from *critic.txt*)

**Strengths**

* ðŸš€  *Efficiency*: FFT reduces complexity to *O(dâ€¯logâ€¯d)*.
* ðŸ§©  *Universality*: handles diverse input shapes & data types.
* ðŸ“¦  *Compactness*: baked hashes shrink memory footprint.

**Key Concerns & Suggested Improvements**

1. **Theoretical Justification** â€“ include formal proof or reference why chosen projection matrices approximate the bilinear kernel; explore JLâ€‘style guarantees (see Â§6.1, Â§6.2).
2. **Practical Stability on Sparse Data** â€“ evaluate and document behaviour; binary projections recommended.
3. **Hyperâ€‘parameter Selection** â€“ add explicit tuning guidelines (see Â§7).
4. **Learnable Projections** â€“ enable `learnable_sketch` & `learnable_phase` (already added in v1.0).
5. **Alternative Approximations** â€“ evaluate NystrÃ¶m, Random Maclaurin; see Â§14 benchmarking plan.
6. **Regularisation** â€“ consider Dropout or BatchNorm on projection matrices for additional robustness.

---

## 22 Â· Open Questions & Planned Work

1. **Ultraâ€‘lowâ€‘rank (<32) bake quality** â€“ investigate ILP & stochastic rounding.
2. **Adaptive perâ€‘group sketch size** â€“ prune output mask Î» at runtime.
3. **Nâ€‘ary fusion gradient tests** â€“ finalise API & stability benchmarks.
4. **Sparse FFT kernels** â€“ exploit `nnz â‰ª dâ€²` to skip zero bins.
5. **Theoretical tight bounds** â€“ derive distributionâ€‘dependent error bounds.

---

## 23 Â· Licensing

Released under **MIT** licence (compatible with PyTorch).

---

## 24 Â· References (combined superset)

```
[1] A. Fukui, D. H. Park, D. Yang, A. Rohrbach, T. Darrell, M. Rohrbach, â€œMultimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding,â€ ECCV 2016. (arXiv:1606.01847)
[2] M. Charikar, K. Chen, M. Farachâ€‘Colton, â€œFinding frequent items in data streams,â€ ICALP 2002.
[3] N. Pham, R. Pagh, â€œFast and Scalable Polynomial Kernels via Explicit Feature Maps,â€ KDD 2013. (arXiv:1307.2977)
[4] I. V. Oseledets, â€œTensorâ€‘Train Decomposition,â€ SIAM J. Sci. Comput. 2011. (arXiv:0908.0052)
[5] F. Morcos, Y. Babenko, N. Shazeer, â€œRandom Maclaurin Features for RNNs,â€ ICML 2019.
[6] A. Sutherland, J. Schneider, â€œLearning to Sketch,â€ ICML 2020. (arXiv:2006.10963)
[7] J. A. Tropp et al., â€œRandomized Numerical Linear Algebra,â€ *Acta Numerica* 2017.
```

---

*Prepared for integration into* **TensorComposerMobius**.  *Feedback & PRs welcome!*